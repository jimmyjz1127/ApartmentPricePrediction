{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements a number of nearest neighbour algorithm for the regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python Imports\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extra non-standard utilities\n",
    "from argparse import Namespace\n",
    "\n",
    "\n",
    "# Data management and Math imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Torch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset \n",
    "import copy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "   seed=5059 \n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"NumpyData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = np.load(dataDir + 'X_train_prepared.npy')\n",
    "X_test_processed = np.load(dataDir + 'X_test_prepared.npy')\n",
    "X_val_processed = np.load(dataDir + 'X_val_prepared.npy')\n",
    "\n",
    "y_train_processed = np.load(dataDir + 'y_train_prepared.npy')\n",
    "y_test_processed = np.load(dataDir + 'y_test_prepared.npy')\n",
    "y_val_processed = np.load(dataDir + 'y_val_prepared.npy')\n",
    "\n",
    "y_train = np.load(dataDir + 'y_train.npy')\n",
    "y_val = np.load(dataDir + 'y_val.npy')\n",
    "y_test = np.load(dataDir + 'y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine val and train - val not needed for K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed =  np.vstack((X_train_processed, X_val_processed))\n",
    "y_train_processed =  np.vstack((y_train_processed, y_val_processed))\n",
    "y_train = np.concatenate((y_train, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 First Principles K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(A, B):\n",
    "    '''\n",
    "        Cosine similarity distance function\n",
    "        @param (A) ; n-dimensional vector (numpy array)\n",
    "        @param (B) : n-dimensional vector (numpy array)\n",
    "    '''\n",
    "\n",
    "    dot_product = np.dot(A, B)\n",
    "    norm_A = np.linalg.norm(A)\n",
    "    norm_B = np.linalg.norm(B)\n",
    "    return dot_product / (norm_A * norm_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_step(data, us, K):\n",
    "    ''' \n",
    "        K-mean assign-step (assign datapoints to clusters)\n",
    "        @param (data) : the data matrix (n x d)\n",
    "        @param (us)   : the cluster means (K x 1)\n",
    "        @param (K)    : the number of clusters\n",
    "    '''\n",
    "\n",
    "    _, N = data.shape\n",
    "\n",
    "    distances = np.array([[cosine_similarity(x, u) for u in us] for x in data])\n",
    "\n",
    "    zs = np.eye(K)[np.argmax(distances, axis=1)]\n",
    "\n",
    "    min_distances = np.sum(np.max(distances, axis=1))\n",
    "\n",
    "    return min_distances,zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_step(data, zs, K):\n",
    "    ''' \n",
    "        K-mean update step (update cluster assignments of each datapoint)\n",
    "        @param (data) : the data matrix (n x d)\n",
    "        @param (zs)   : the datapoint assignments ()\n",
    "        @param (K)    : the number of clusters\n",
    "    '''\n",
    "\n",
    "    _, d = data.shape\n",
    "\n",
    "    combined = np.dot(data.T, zs).T\n",
    "    sums = np.sum(zs, axis=0)\n",
    "\n",
    "    for i in range(0,K):\n",
    "        combined[i] *= 1/sums[i]\n",
    "\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(data, K=20, tol= 1e-4, maxIters= 100):\n",
    "    ''' \n",
    "        K-Means assign-update learning algorithm \n",
    "        @param (data) : the data matrix (n x d)\n",
    "        @param (K) : the number of clusters to assume\n",
    "        @param (tol) : the convergence check loss amount\n",
    "        @param (maxIters) : maximum iterations to perform before stopping\n",
    "    '''\n",
    "\n",
    "\n",
    "    n, d = data.shape \n",
    "\n",
    "    init_us_ids = rng.integers(n, size = K)\n",
    "\n",
    "    us = data[init_us_ids, :]\n",
    "\n",
    "    zs = np.zeros(n)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    # loop until converge \n",
    "    for i in range(maxIters):\n",
    "        # assignment step\n",
    "        min_distances, zs = assign_step(data,us,K)\n",
    "        \n",
    "        # update step\n",
    "        us = update_step(data,zs,K)\n",
    "\n",
    "        # convergence check  \n",
    "        losses.append(1 - min_distances)      \n",
    "\n",
    "        if i > 1 and np.abs(losses[i] - losses[i-1]) < tol : break\n",
    "\n",
    "    return losses, zs, us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_results(trials, X):\n",
    "    ''' \n",
    "        Runs a number of trials of kmeans to produce cluster assignments with the lowest loss\n",
    "\n",
    "        @param (trials) : integer number of trials to run\n",
    "        @param (X) : the data matrix\n",
    "    '''\n",
    "\n",
    "    best = np.inf\n",
    "    l = None\n",
    "    z = None\n",
    "    u = None\n",
    "    for i in range(0,trials):\n",
    "        losses, zs, us = kmeans(X)\n",
    "        mean_loss = np.mean(losses)\n",
    "        if mean_loss < best:\n",
    "            best = mean_loss\n",
    "            l = losses\n",
    "            z = zs\n",
    "            u = us \n",
    "\n",
    "    return l, z, u"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
