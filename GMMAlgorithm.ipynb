{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements a GMM for the regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python Imports\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extra non-standard utilities\n",
    "from argparse import Namespace\n",
    "\n",
    "\n",
    "# Data management and Math imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Torch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset \n",
    "import copy\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.πspeline import πspeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "   seed=5059 \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"NumpyData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = np.load(dataDir + 'X_train_prepared.npy')\n",
    "X_test_processed = np.load(dataDir + 'X_test_prepared.npy')\n",
    "X_val_processed = np.load(dataDir + 'X_val_prepared.npy')\n",
    "\n",
    "y_train_processed = np.load(dataDir + 'y_train_prepared.npy')\n",
    "y_test_processed = np.load(dataDir + 'y_test_prepared.npy')\n",
    "y_val_processed = np.load(dataDir + 'y_val_prepared.npy')\n",
    "\n",
    "y_train = np.load(dataDir + 'y_train.npy')\n",
    "y_val = np.load(dataDir + 'y_val.npy')\n",
    "y_test = np.load(dataDir + 'y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine train and validation data - no need for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed =  np.vstack((X_train_processed, X_val_processed))\n",
    "y_train_processed =  np.vstack((y_train_processed, y_val_processed))\n",
    "y_train = np.concatenate((y_train, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 First principles GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Expectation Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Log Likelihood\n",
    "$$\\begin{align}\n",
    "    P(x|\\sigma_k^2,\\mu_k) = -\\frac{n}{2}\\ln(2\\pi\\sigma^{2}_k) - \\frac{1}{2\\sigma^{2}}\\sum_{i=1}^n (x - \\mu_k)^2\n",
    "\\end{align}$$\n",
    "Hence we have responsibility assignment:\n",
    "$$\\begin{align}\n",
    "    r_{ik} = \\ln\\pi_k - \\frac{d}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln|\\Sigma_{k}| - \\frac{1}{2}(x^{(i)} - \\mu_k)^{T}\\Sigma_{k}^{-1}(x^{(i)} - \\mu_k) \\\\ - \\ln \\left \\{ \\sum_{k'}^{K} \\pi_{k'} + \\exp \\left \\{ -\\frac{1}{2}(x^{(i)} - \\mu_{k'})^{T}\\Sigma_{k'}^{-1}(x^{(i)} - \\mu_{k'}) \\right \\} \\right \\} \n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def e_step(X, πs, μs, Σs, eps=1e-14):\n",
    "\n",
    "    n, d = X.shape\n",
    "    K = len(πs)\n",
    "    \n",
    "    # Responsibility matrix\n",
    "    R = np.zeros((n, K))\n",
    "    \n",
    "    for k in range(K):\n",
    "        # Calculate the inverse of the covariance matrix and its determinant\n",
    "        sigma_inv = np.linalg.inv(Σs[k])\n",
    "        sigma_det = np.linalg.det(Σs[k])\n",
    "        \n",
    "        # Compute the log-likelihood for each data point and each cluster\n",
    "        diff = X - μs[k]  # Shape (n, d)\n",
    "        exponent = np.sum(diff @ sigma_inv * diff, axis=1)  # Shape (n,)\n",
    "        \n",
    "        # Log of the Gaussian component likelihood\n",
    "        log_likelihood_k = -0.5 * (d * np.log(2 * np.pi) + np.log(sigma_det) + exponent)\n",
    "        \n",
    "        # Update responsibility matrix using the log of the likelihood\n",
    "        R[:, k] = np.log(πs[k] + eps) + log_likelihood_k\n",
    "    \n",
    "    # Compute the log-sum-exp to normalize the responsibilities (numerically stable)\n",
    "    log_R_norm = np.log(np.sum(np.exp(R), axis=1, keepdims=True) + eps)\n",
    "    \n",
    "    # Normalize the responsibilities so they sum to 1 across clusters for each data point\n",
    "    R = np.exp(R - log_R_norm)  # This is the responsibility matrix\n",
    "    \n",
    "    # Compute the total log-likelihood of the data\n",
    "    loglik = np.sum(log_R_norm)  # Sum of the log of the norm across all data points\n",
    "    \n",
    "    return R, loglik\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Maximization Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update $\\mu_{k}$, $\\pi_{k}$, $\\Sigma_{k}$ : \n",
    "$$\\begin{align}\n",
    "    \\mu_{k} &= \\frac{1}{\\sum^{n}_{i=1} r_{ik}}\\\\\n",
    "    \\pi_{k} &= \\frac{1}{n} \\sum^{n}_{i=1} r_{ik}\\\\\n",
    "    \\Sigma_{k} &= \\frac{1}{\\sum^{n}_{i=1} r_{ik}} \\sum^{n}_{i=1}r_{ik}(x^{(i)}-\\mu_{k})(x^{(i)}-\\mu_{k})^T\n",
    "\\end{align}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_step(X, R):\n",
    "    n, d = X.shape  # n is number of data points, d is the dimensionality\n",
    "    K = R.shape[1]  # K is the number of components (clusters)\n",
    "    \n",
    "    # Initialize parameters\n",
    "    pi = np.zeros(K)\n",
    "    mu = np.zeros((K, d))\n",
    "    sigma = np.zeros((K, d, d))\n",
    "    \n",
    "    # Update the priors (weights) pi_k\n",
    "    pi = np.sum(R, axis=0) / n\n",
    "    \n",
    "    # Update the means (mu_k) for each component\n",
    "    for k in range(K):\n",
    "        mu[k] = np.sum(R[:, k][:, np.newaxis] * X, axis=0) / np.sum(R[:, k])\n",
    "    \n",
    "    # Update the covariance matrices (Sigma_k) for each component\n",
    "    for k in range(K):\n",
    "        diff = X - mu[k]\n",
    "        sigma[k] = np.dot((R[:, k][:, np.newaxis] * diff).T, diff) / np.sum(R[:, k])\n",
    "    \n",
    "    return pi, mu, sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
