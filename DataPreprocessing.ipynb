{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    save_directory=\"NumpyData/Apartment/\",\n",
    "    data_path = \"./apartments_small.csv\",\n",
    "    train_split = 0.8,\n",
    "    test_split = 0.2,\n",
    "    val_split=0.25,\n",
    "    seed=5059,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(args.data_path, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 22)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 int64\n",
       "category          object\n",
       "title             object\n",
       "body              object\n",
       "amenities         object\n",
       "bathrooms        float64\n",
       "bedrooms           int64\n",
       "currency          object\n",
       "fee               object\n",
       "has_photo         object\n",
       "pets_allowed      object\n",
       "price              int64\n",
       "price_display     object\n",
       "price_type        object\n",
       "square_feet        int64\n",
       "address           object\n",
       "cityname          object\n",
       "state             object\n",
       "latitude         float64\n",
       "longitude        float64\n",
       "source            object\n",
       "time               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                      5668610646\n",
       "category                                    housing/rent/apartment\n",
       "title                                 Three BR 128 Magazine Street\n",
       "body             This unit is located at 128 Magazine Street, D...\n",
       "amenities                                  Dishwasher,Refrigerator\n",
       "bathrooms                                                      2.0\n",
       "bedrooms                                                         3\n",
       "currency                                                       USD\n",
       "fee                                                             No\n",
       "has_photo                                                Thumbnail\n",
       "pets_allowed                                             Cats,Dogs\n",
       "price                                                         1149\n",
       "price_display                                               $1,149\n",
       "price_type                                                 Monthly\n",
       "square_feet                                                   1340\n",
       "address                                            128 Magazine St\n",
       "cityname                                                    Dallas\n",
       "state                                                           GA\n",
       "latitude                                                   33.9217\n",
       "longitude                                                 -84.8634\n",
       "source                                                   RentLingo\n",
       "time                                                    1577358343\n",
       "Name: 8623, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''  \n",
    "    Custom Estimators \n",
    "'''\n",
    "\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    ''' \n",
    "        Drop : default, poutcome\n",
    "    '''\n",
    "    def __init__(self, columns_to_drop):\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        return X_copy.drop(columns=self.columns_to_drop)\n",
    "\n",
    "class ExplodeHotEncode(BaseEstimator, TransformerMixin):\n",
    "    ''' \n",
    "        Explodes and onehot-encodes series type columns (values in series become separate binarized columns)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, columns, sep=\",\"):\n",
    "        self.columns = columns\n",
    "        self.sep = sep \n",
    "        self.encoders = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        X_copy = X.copy()\n",
    "        for col in self.columns:\n",
    "            token_lists = X_copy[col].astype(str).apply(lambda x: list(set(x.split(self.sep))) if not self.isNa(x) else [])\n",
    "\n",
    "            mlb = MultiLabelBinarizer()\n",
    "            mlb.fit(token_lists)\n",
    "            self.encoders[col] = mlb\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "\n",
    "        for col in self.columns:\n",
    "            token_lists = X_copy[col].astype(str).apply(lambda x: list(set(x.split(self.sep))) if not self.isNa(x) else [])\n",
    "            mlb = self.encoders[col]\n",
    "            transformed = mlb.transform(token_lists)\n",
    "            df_transformed = pd.DataFrame(transformed, \n",
    "                                          columns=[f\"{col}__{cls}\" for cls in mlb.classes_],\n",
    "                                          index=X_copy.index)\n",
    "            \n",
    "            X_copy = pd.concat([X_copy, df_transformed], axis=1)\n",
    "            \n",
    "        X_copy = X_copy.drop(columns=self.columns)\n",
    "\n",
    "        return X_copy\n",
    "    \n",
    "    def isNa(self, x) :\n",
    "        return x.strip() == \"\" or x is None or x.lower() == \"nan\"\n",
    "    \n",
    "class HandleNaN(BaseEstimator, TransformerMixin):\n",
    "    ''' \n",
    "        Standardizes missing values to np.nan type\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X,):\n",
    "        X_copy = X.copy()\n",
    "        X_copy = X_copy.map(lambda x : x.lower().strip() if isinstance(x, str) else x)\n",
    "        X_copy.replace('unknown', np.nan, inplace=True)\n",
    "        X_copy.replace('nonexistent', np.nan, inplace=True)\n",
    "\n",
    "        X_copy.ffill(inplace=True) \n",
    "\n",
    "        return X_copy\n",
    "    \n",
    "\n",
    "class EncodeStateToRegion(BaseEstimator, TransformerMixin):\n",
    "    ''' \n",
    "        Reduces states to regions\n",
    "    '''\n",
    "\n",
    "    def __init__(self, column=\"state\"):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "\n",
    "        D1 = [\"CT\", \"ME\", \"MA\", \"NH\", \"RI\", \"VT\"]\n",
    "        D2 = [\"NJ\", \"NY\", \"PA\"]\n",
    "        D3 = [\"IL\", \"IN\", \"MI\", \"OH\", \"WI\"]\n",
    "        D4 = [\"IA\", \"KS\", \"MN\", \"MO\", \"NE\", \"ND\", \"SD\"]\n",
    "        D5 = [\"DE\", \"FL\", \"GA\", \"MD\", \"NC\", \"SC\", \"VA\", \"DC\", \"WV\"]\n",
    "        D6 = [\"AL\", \"KY\", \"MS\", \"TN\"]\n",
    "        D7 = [\"AR\", \"LA\", \"OK\", \"TX\"]\n",
    "        D8 = [\"AZ\", \"CO\", \"ID\", \"MT\", \"NV\", \"NM\", \"UT\", \"WY\"]\n",
    "        D9 = [\"AK\", \"CA\", \"HI\", \"OR\", \"WA\"]\n",
    "\n",
    "        self.choices = [\"New_England\",\"Mid_Atlantic\",\"E_N_Central\",\"W_N_Central\",\"South_Atlantic\",\n",
    "            \"E_S_Central\",\"W_S_Central\",\"Mountain\",\"Pacific\"]\n",
    "\n",
    "        conditions = [\n",
    "                    (X[self.column].isin(D1)),\n",
    "                    (X[self.column].isin(D2)),\n",
    "                    (X[self.column].isin(D3)),\n",
    "                    (X[self.column].isin(D4)),\n",
    "                    (X[self.column].isin(D5)),\n",
    "                    (X[self.column].isin(D6)),\n",
    "                    (X[self.column].isin(D7)),\n",
    "                    (X[self.column].isin(D8)),\n",
    "                    (X[self.column].isin(D9)),\n",
    "                ]\n",
    "\n",
    "        X_copy['region'] = np.select(conditions, self.choices)\n",
    "        X_copy = X_copy.drop(columns=self.column)\n",
    "\n",
    "        return X_copy\n",
    "    \n",
    "\n",
    "    \n",
    "class EncodeCityPrice(BaseEstimator, TransformerMixin):\n",
    "    ''' \n",
    "        For encoding cities into city price categories\n",
    "        2 : high\n",
    "        1 : med\n",
    "        0 : low\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        cities = X.groupby(['cityname'])[['price']].mean()\n",
    "\n",
    "        # make a judgement of where to split into low medium high price cities\n",
    "        self.high_cities = cities[cities['price']>2000].index\n",
    "        self.low_cities = cities[cities['price']<1000].index\n",
    "        # I'm going to say below <1000 is low and >2000 is high, \n",
    "        # you could use any other split you think is a good idea\n",
    "        \n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        \n",
    "\n",
    "        city_conditions = [\n",
    "            (X_copy['cityname'].isin(self.high_cities)),\n",
    "            (X_copy['cityname'].isin(self.low_cities)),\n",
    "        ]\n",
    "        city_choices = [2, 0]\n",
    "        \n",
    "        \n",
    "\n",
    "        X_copy['cityprice'] = np.select(city_conditions, city_choices, default=1)\n",
    "\n",
    "        X_copy = X_copy.drop(columns=[\"cityname\", \"price\"])\n",
    "\n",
    "        return X_copy   \n",
    "\n",
    "\n",
    "class Binarize(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        \n",
    "        # Convert all instances of \"yes\"/\"success\" and \"no\"/\"failure\" to numbers 1 and 0\n",
    "        X_copy = X_copy.map(lambda x: 1 if x == 'yes' or x=='success' else (0 if x == 'no' or x=='failure'else x))\n",
    "\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['id','bathrooms','bedrooms','square_feet','latitude','longitude','time']\n",
    "categorical_columns = ['title','body','currency','price_display','address', 'pets_allowed','category','amenities','cityname','price']\n",
    "onehot_columns = ['has_photo', 'price_type', 'source', 'state']\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('drop', DropColumns(columns_to_drop=['id'])),\n",
    "    ('impute', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('drop', DropColumns(columns_to_drop=['title','body','currency','price_display','address'])),\n",
    "    ('binarize', Binarize()),\n",
    "    (\"handleNaN\", HandleNaN()),\n",
    "    ('explodeHotEncodeComma', ExplodeHotEncode(['amenities', 'pets_allowed'], ',')),\n",
    "    ('explodeHotEncodeSlash', ExplodeHotEncode(['category'], '/')),\n",
    "    ('encodeCityPrice', EncodeCityPrice())\n",
    "])\n",
    "\n",
    "onehot_pipeline = Pipeline([\n",
    "    (\"handleNaN\", HandleNaN()),\n",
    "    ('stateToRegion', EncodeStateToRegion()),\n",
    "    ('onehot', OneHotEncoder(drop=\"first\", handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('numerical', numerical_pipeline, numerical_columns),\n",
    "    ('categorical', categorical_pipeline, categorical_columns),\n",
    "    ('onehot', onehot_pipeline, onehot_columns),\n",
    "])\n",
    "\n",
    "labelScaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/home/jz75/Documents/ML/myenv/lib64/python3.9/site-packages/sklearn/preprocessing/_label.py:909: UserWarning: unknown class(es) ['alarm'] will be ignored\n",
      "  warnings.warn(\n",
      "/cs/home/jz75/Documents/ML/myenv/lib64/python3.9/site-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "/cs/home/jz75/Documents/ML/myenv/lib64/python3.9/site-packages/sklearn/preprocessing/_label.py:909: UserWarning: unknown class(es) ['doorman'] will be ignored\n",
      "  warnings.warn(\n",
      "/cs/home/jz75/Documents/ML/myenv/lib64/python3.9/site-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n",
      "/cs/home/jz75/Documents/ML/myenv/lib64/python3.9/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y = df['price'].copy()\n",
    "X = df.copy()\n",
    "\n",
    "# Create Splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=args.test_split, random_state=args.seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=args.val_split, random_state=args.seed)\n",
    "\n",
    "# Pre-process Data \n",
    "X_train_prepared = full_pipeline.fit_transform(X_train)\n",
    "X_val_prepared = full_pipeline.transform(X_val)\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "\n",
    "y_train_prepared = labelScaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_prepared = labelScaler.fit_transform(y_test.values.reshape(-1, 1))\n",
    "y_val_prepared = labelScaler.fit_transform(y_val.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "np.save(args.save_directory + 'X_train_prepared.npy', X_train_prepared)\n",
    "np.save(args.save_directory + 'X_test_prepared.npy', X_test_prepared)\n",
    "np.save(args.save_directory + 'X_val_prepared.npy', X_val_prepared)\n",
    "\n",
    "# Raw Labels\n",
    "np.save(args.save_directory + 'y_train.npy', y_train)\n",
    "np.save(args.save_directory + 'y_test.npy', y_test)\n",
    "np.save(args.save_directory + 'y_val.npy', y_val)\n",
    "\n",
    "# Processed Labels\n",
    "np.save(args.save_directory + 'y_train_prepared.npy', y_train_prepared)\n",
    "np.save(args.save_directory + 'y_test_prepared.npy', y_test_prepared)\n",
    "np.save(args.save_directory + 'y_val_prepared.npy', y_val_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
